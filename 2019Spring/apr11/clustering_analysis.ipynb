{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Study Group\n",
    "## April 11th, 2019\n",
    "\n",
    "### Using pandas to analyze tab-delimited or comma-delimited data (tables).\n",
    "\n",
    "Pandas (**Pan**eled **da**taframe**s**) is a powerful python module capable of efficiently writing, reading, navigating and munging data tables.\n",
    "\n",
    "We will cover:\n",
    "\n",
    "1. Reading in data\n",
    "2. Data munging\n",
    "    - Removing duplicates\n",
    "    - Transitioning from a pandas dataframe to a python built-in datastructure\n",
    "3. Writing data\n",
    "\n",
    "\n",
    "Examples: \n",
    "\n",
    "1. Given Metagenomics binning output (Autometa) determine the heterogeneity of a binned genome.\n",
    "2. Determine the number of shared single-copy marker genes between clusters.\n",
    "3. Determine what single-copy marker genes are duplicated in a genome bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The conventional method of importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Some other tools for visualizing our data..\n",
    "from matplotlib import pyplot as plt # boring\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n1 data/ML_recruitment_output.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily explore a taxonomy table generated from Autometa...\n",
    "df = pd.read_csv('data/ML_recruitment_output.tab', sep='\\t', index_col='contig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a nice one-liner that allows you to group all of the clusters into each of their respective dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily see what columns we can look up with the columns method.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determining bin heterogeneity\n",
    "\n",
    "We will determine the different taxa within a genome bin by first grouping each contig by its named cluster. In this case we will use the column from the decision tree classifier output table from Autometa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = dict(list(df.groupby('ML_expanded_clustering')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may explore the dataframe using the index locator method or by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can easily visually explore the autometa clustering using seaborn to build a scatter plot\n",
    "sns.lmplot(x='bh_tsne_x', y='bh_tsne_y', data=df, \n",
    "           hue='ML_expanded_clustering', \n",
    "#            markers=['o','x','v'],\n",
    "           palette='Set1',\n",
    "           fit_reg=False,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, cluster_df in clusters.items():\n",
    "    print('{} unique genus in {}:\\n{}'.format(cluster_df['genus'].nunique(), cluster, cluster_df.genus.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets continue on with clusters 'DBSCAN_round1_9' and 'DBSCAN_round1_0' as they both have been classified under the genus _Nocardia_.\n",
    "\n",
    "Let us determine the number of shared single-copy marker genes between the two clusters, see if there exists duplicates and see if each has their own unique set.\n",
    "\n",
    "We can determine other genome properties such as the total size of the cluster and even mean GC percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily determine the length in one line. First let's compare the two by size\n",
    "print('size of DBSCAN_round1_0:',df[df.ML_expanded_clustering == 'DBSCAN_round1_0'].length.sum(), 'bp')\n",
    "\n",
    "print('size of DBSCAN_round1_9:',df[df.ML_expanded_clustering == 'DBSCAN_round1_9'].length.sum(), 'bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see these genome bins vary significantly in size (5,526,970 bps to be exact!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us determine the number of single-copy marker genes in each bin and which are shared or unique between the genome bins.\n",
    "\n",
    "First we will need to retrieve the single-copy marker genes specific to each genome bin.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recall we have single_copy_PFAMs as a column id to look up\n",
    "df[df.ML_expanded_clustering == 'DBSCAN_round1_9'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ML_expanded_clustering == 'DBSCAN_round1_9'].single_copy_PFAMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice cells with missing values have NaN and the other cells contain a comma-delimited list of single-copy PFAM annotations. Let's overlook the NaN contigs so we can more closely inspect the number of contigs within the cluster that contain the marker genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ML_expanded_clustering == 'DBSCAN_round1_9'].single_copy_PFAMs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_contigs = len(df[df.ML_expanded_clustering == 'DBSCAN_round1_9'].single_copy_PFAMs.dropna())\n",
    "print('num contigs containing marker genes: {}'.format(n_contigs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same method for our other _Nocardia_ cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ML_expanded_clustering == 'DBSCAN_round1_0'].single_copy_PFAMs.dropna()\n",
    "n_contigs = len(df[df.ML_expanded_clustering == 'DBSCAN_round1_0'].single_copy_PFAMs.dropna())\n",
    "print('num contigs containing marker genes: {}'.format(n_contigs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us determine the shared set of single-copy marker genes from these 19 and 16 contigs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_copies = clusters['DBSCAN_round1_9'].num_single_copies.sum()\n",
    "print('num single copies cluster DBSCAN_round1_9: {}'.format(n_copies))\n",
    "n_copies = clusters['DBSCAN_round1_0'].num_single_copies.sum()\n",
    "print('num single copies cluster DBSCAN_round1_0: {}'.format(n_copies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note this will generate a list of list of PFAMs separated by commas.\n",
    "pfams = clusters['DBSCAN_round1_0'].single_copy_PFAMs.dropna().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the list with a list comprehension.. \n",
    "This will take each element of the PFAMs list (a list of csv pfams)\n",
    "and split this element into a list of pfams..\n",
    "Finally these elements (the individual PFAMs) will be placed into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pfams = [p for pfam in pfams for p in pfam.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can determine the number of pfams as well as the number unique in the pfams with the built-in set function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number:',len(all_pfams))\n",
    "print('num unique:',len(set(all_pfams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pfams from cluster 1_9\n",
    "pfams = clusters['DBSCAN_round1_9'].single_copy_PFAMs.dropna().tolist()\n",
    "nocardia1 = [p for pfam in pfams for p in pfam.split(',')]\n",
    "print('num pfams in DBSCAN_round1_9: {}'.format(len(nocardia1)))\n",
    "# Get pfams from cluster 1_0\n",
    "pfams = clusters['DBSCAN_round1_0'].single_copy_PFAMs.dropna().tolist()\n",
    "nocardia2 = [p for pfam in pfams for p in pfam.split(',')]\n",
    "print('num pfams in DBSCAN_round1_0: {}'.format(len(nocardia2)))\n",
    "n1 = set(nocardia1)\n",
    "n2 = set(nocardia2)\n",
    "print('unique pfams in DBSCAN_round1_0: {}'.format(len(set(nocardia2))))\n",
    "print('unique pfams in DBSCAN_round1_9: {}'.format(len(set(nocardia1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting = n1.intersection(n2)\n",
    "# interseting = n1 & n2\n",
    "print('num shared markers: {}'.format(len(intersecting)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2_uniques = n2 - n1\n",
    "print('{} PFAMs unique to DBSCAN_round1_0'.format(len(n2_uniques)))\n",
    "n1_uniques = n1 - n2\n",
    "print('{} PFAMs unique to DBSCAN_round1_9'.format(len(n1_uniques)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_pfams = n2 & n1\n",
    "print('{} PFAMs shared between clusters'.format(len(shared_pfams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine what of the \"single-copy\" marker genes are found as duplicates in these genome bins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1_dups = [pfam for pfam in nocardia1 if nocardia1.count(pfam) > 1]\n",
    "n2_dups = [pfam for pfam in nocardia2 if nocardia2.count(pfam) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DBSCAN_round1_9')\n",
    "print(n1_dups)\n",
    "print('DBSCAN_round1_0')\n",
    "print(n2_dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we would like to write out clusters as their own individual table. we may us \\*.the to_csv() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, c_df in clusters.items():\n",
    "    outfile = 'data/{}.tsv'.format(c)\n",
    "    c_df.to_csv(outfile, sep='\\t', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see we have written out a tab-delimited file corresponding to each cluster.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
